---
title: "Permutation Tests with Multinomial Logistic Regression"
author: "Nicole Johnson"
date: "2024-05-08"
categories: [code, statistics]
image: "graph1.JPG"
---

This tutorial will guide you through the implementation of permutation testing for assessing the significance of coefficients in a multinomial logistic regression model using R. The function `calc_pval` is provided for this purpose, which we will dissect step by step to understand its components and usage.

## Overview of Permutation Testing

Permutation testing is a versatile non-parametric statistical tool that allows researchers to test hypotheses about relationships within their data without relying on traditional assumptions about the underlying distribution of the data. This method is particularly useful in fields where the normality assumption does not hold or is difficult to verify.

### Principle of Permutation Testing

At its core, permutation testing involves randomly rearranging (permuting) the labels or values of a dataset and recalculating the statistic of interest, such as a correlation coefficient or regression coefficient, across many such rearranged samples. The idea is to generate a distribution of the statistic under the null hypothesis, which states that there is no association between the variables being tested.

### Steps in Permutation Testing

1.  **Define the Test Statistic**: First, identify the statistic that you will use to measure the association between variables. In the case of regression analysis, this could be the coefficients of the regression model.

2.  **Calculate the Observed Statistic**: Compute the test statistic with the original, unpermuted data. This gives you the observed value that you will compare against the results of the permuted datasets.

3.  **Permute and Recalculate**: Shuffle or permute the outcome variable or the labels of the data while keeping the structure of the data otherwise the same. Then, recalculate the test statistic for this permuted data. This process is repeated a large number of times (commonly 1,000 or more) to build up a distribution of the statistic under the null hypothesis.

4.  **Determine Significance**: Compare your observed test statistic to the distribution obtained from the permuted data. The p-value is calculated as the proportion of permuted statistics that are as extreme as or more extreme than the observed statistic. A small p-value (typically less than 0.05) suggests that the observed association is unlikely to have occurred by chance under the null hypothesis.

## Advantages of Permutation Testing for Multinomial Regressions

### But first, what is multinomial regression?

In binary logistic regression, the outcome is typically modeled with a logistic function predicting the probability of one of the two categories, given a set of independent variables. Multinomial logistic regression generalizes this approach to multiple categories by using a series of logistic equations to compare each category to a reference category. The probabilities derived from these equations are relative to the reference category, which is usually chosen automatically by the software or can be manually specified.

#### Model Formulation

The model estimates the probabilities of being in each category of the dependent variable as a function of the independent variables. It does this through what are known as the log-odds or logit transformations, where each category (except the reference category) will have its own set of regression coefficients.

Mathematically, if you have a response variable (Y) with (K) possible outcomes, the probability of (Y) equaling a particular category (k) can be modeled as:

\[ P(Y = k \mid X) = \frac{e^{\beta_{k0} + \beta_{k1}X_1 + \cdots + \beta_{kp}X_p}}{1 + \sum_{j=1}^{K-1} e^{\beta_{j0} + \beta_{j1}X_1 + \cdots + \beta_{jp}X_p}} \]

where (X_1, X_2, \ldots, X_p) are the predictor variables, and (\beta*{k0},\* \beta{k1}, \ldots, \beta\_{kp}) are the coefficients for category (k).

#### Estimation

The coefficients (\beta\_{kj}) are typically estimated using maximum likelihood estimation (MLE). This method seeks to find the set of coefficients that maximize the likelihood of observing the sample given the model.

#### Interpretation

Interpreting the coefficients in multinomial logistic regression is similar to binary logistic regression, but instead of comparing the log-odds of the outcome to a "no event" condition, each coefficient represents the log-odds of being in the target category relative to the reference category, given a one-unit change in the predictor.

### Applying Permutation Testing

Permutation testing is particularly suited for calculating p-values in the context of multinomial logistic regression for several reasons. This method provides robust and reliable significance testing that can be superior to traditional methods, especially when standard assumptions are violated or when the data structure is complex.

1.  **Non-Parametric Approach:** Multinomial logistic regression models, which predict categorical outcomes with more than two categories, often struggle with issues like non-normality of residuals and complex, nonlinear relationships between variables. Permutation testing is a non-parametric technique, meaning it does not rely on assumptions about the distribution of the variables or the form of the model. This characteristic makes it highly suitable for the categorical nature of the data in multinomial logistic regression, where such assumptions cannot be validated easily.
2.  **Empirical P-values:** Permutation testing generates empirical p-values based on the data itself, rather than relying on theoretical distributions. This is done by repeatedly shuffling the outcome variable and recalculating the model coefficients for each shuffled dataset. By comparing the observed coefficients to those from these permuted datasets, we can directly observe how extreme the actual coefficients are within the context of a null hypothesis where no predictors have a real effect on the outcomes. This direct approach is particularly useful in complex models where theoretical distributions may not adequately reflect the reality of the data.
3.  **Handling Complex Model Structures:** In multinomial logistic regression, dealing with multiple outcomes and potentially a large set of predictors can introduce complexity in interpreting interaction effects and the overall significance of predictors. Permutation testing simplifies this by treating the model as a whole during the permutation process, maintaining the structure of the data but breaking any real association between the predictors and the outcomes by shuffling. This method allows for an intuitive assessment of whether observed relationships in the data are likely to be due to chance.
4.  **Robustness Against Overfitting and Model Assumptions:** Multinomial logistic models can easily overfit, especially with a large number of predictors or complex interactions. Standard tests might falsely indicate predictors as significant due to overfitting or other violations of model assumptions (like independence of observations, homoscedasticity, etc.). Permutation testing does not assume these conditions and inherently provides a check against overfitting by evaluating how the model performance (through its coefficients) holds up under randomized conditions.
5.  **Flexibility and Adaptability:** Permutation testing is adaptable to various model specifications and data structures without the need for adjusting the fundamental approach. Whether dealing with highly imbalanced classes, different sample sizes, or unusual data distributions, permutation testing remains applicable and reliable, making it a versatile tool in statistical analysis.
6.  **Validation of Statistical Significance:** Using permutation testing to calculate p-values provides a straightforward and conceptually simple method to validate the statistical significance of coefficients in a multinomial logistic regression. This method can be particularly persuasive when presenting findings to a broader audience, including those who may not be familiar with the intricacies of more complex statistical methodologies.

## Tutorial on Permutation Testing for P-Values in Multinomial Regression

### Function Description: `calc_pval`

The function `calc_pval` performs a permutation test on a multinomial logistic regression model fitted with specified predictors and an outcome. The function requires several inputs: - `df`: A dataframe containing the data. - `outcome`: The name of the outcome variable in the dataframe. - `predictors`: A vector of predictor variables. - `nreps`: The number of permutations to perform.

### Function Breakdown

1.  **Creating the Model Formula**:

    -   Constructs a formula for the multinomial logistic regression model using the outcome and predictors.

    ``` r
    f <- formula(paste(outcome, paste(predictors, collapse = " + "), sep = " ~ "))
    print(f)
    ```

2.  **Fitting the Model**:

    -   Fits a multinomial logistic regression model using the `multinom` function from the `nnet` package. This model is our "observed" model.

    ``` r
    model <- multinom(formula=f, data=df, family="binomial")
    ```

3.  **Permutation Testing**:

    -   Initializes a loop to perform `nreps` permutations of the outcome variable.
    -   For each permutation, it shuffles the outcome variable, fits a new model, and stores the coefficients.

    ``` r
    while (i < nreps){
      loop_df <- data.frame(df)
      loop_df[, outcome] <- sample(loop_df[, outcome])
      loop_model <- multinom(formula=f, data=loop_df, family="binomial", trace=FALSE)
      coefs_null[, , i + 1] <- summary(loop_model)$coefficients
      i <- i + 1
    }
    ```

4.  **Calculating P-Values**:

    -   Compares the observed coefficients to the distribution of coefficients from the permuted data.
    -   Calculates two-tailed p-values for each coefficient by finding how often the permuted coefficients are as extreme as the observed coefficients.

    ``` r
    for (lev in model$lev[-1]){ # excluding the reference category
      null_class <- coefs_null[lev, , ]
      for (coefname in model$coefnames){
        coef_measured <- summary(model)$coefficients[lev, coefname]
        coef_left <- min(coef_measured, -coef_measured)
        coef_right <- max(coef_measured, -coef_measured)
        coef_pleft <- sum(null_class[coefname, ]<=coef_left) / nreps
        coef_pright <- sum(null_class[coefname, ]>=coef_right) / nreps
        row_pvals <- c(row_pvals, coef_pleft + coef_pright)
      }
      pvals[n,] <- row_pvals
      n <- n + 1
    }
    ```

### Usage

To use `calc_pval`, you need a dataframe `df` that includes at least one categorical outcome variable and one or more predictor variables. Specify the outcome variable, a list of predictor variable names, and the number of permutations you want to perform. Here's an example call:

``` r
result_pvals <- calc_pval(df = your_data, outcome = "YourOutcomeVariable", predictors = c("Predictor1", "Predictor2"), nreps = 1000)
print(result_pvals)
```

### Example Dataset: College Major Choice

Suppose we have a dataset from a survey of college students. The dataset includes the following variables:

-   **Major**: The student's chosen major (Business, Engineering, Humanities - categorical, with Humanities as the reference category).
-   **Math_Score**: Score on a mathematics aptitude test (continuous).
-   **Verbal_Score**: Score on a verbal aptitude test (continuous).
-   **Gender**: Male or Female (binary, categorical).

We want to model the probability of a student choosing Business or Engineering over Humanities, based on their math and verbal scores and gender.

### Building the Model

Using R, we can specify our multinomial logistic regression model like this:

``` r
library(nnet)  

model <- multinom(Major ~ Math_Score + Verbal_Score + Gender, data = df)
```

### Model Output Interpretation

The output of the model would give us a set of coefficients for Business and Engineering, relative to Humanities. Here's how you might interpret these coefficients:

-   **Intercept for Business**: The log-odds of choosing Business over Humanities when all other variables are zero.
-   **Math_Score for Business**: The change in log-odds of choosing Business over Humanities for a one-unit increase in Math_Score, holding other variables constant.
-   **Verbal_Score for Business**: Similar to Math_Score, but for Verbal_Score.
-   **Gender for Business**: The change in log-odds of choosing Business over Humanities if the student is male (assuming 'Male' is coded as 1).

### Example Interpretation:

Let's say the coefficients for Business relative to Humanities are as follows:

-   Intercept: -1.50
-   Math_Score: 0.10
-   Verbal_Score: 0.05
-   Gender (Male): 0.25

This means: - For every one-point increase in Math_Score, the log-odds of choosing Business over Humanities increases by 0.10. - Being male increases the log-odds of choosing Business over Humanities by 0.25 compared to being female.

### Permutation Testing

Permutation testing in this context would involve: 1. **Calculating the Observed Statistic**: Compute the regression coefficients with the original data. 2. **Permutation**: Randomly shuffle the Major categories among the students while keeping the predictors the same. 3. **Recompute Coefficients**: Fit the regression model to each permuted dataset and calculate the coefficients. 4. **Comparison and P-Value Calculation**: Compare the observed coefficients to those obtained from the permuted datasets. The p-value for each coefficient is calculated as the proportion of times the permuted coefficients are as extreme as or more extreme than the observed coefficients.

### Interpreting the Permutation Test:

Suppose the p-value for the Gender (Male) coefficient in choosing Business over Humanities is 0.03. This suggests that the observed relationship between gender and major choice is statistically significant at a conventional alpha level of 0.05 (i.e., there is only a 3% chance that such an extreme coefficient would be observed if there was no actual association between gender and major choice).

### I hope this was helpful!

Permutation testing offers a robust and adaptable approach to evaluating the significance of predictors in multinomial logistic regression models. By utilizing the `calc_pval` function as demonstrated in this tutorial, researchers can leverage this non-parametric method to conduct hypothesis testing without relying on the assumptions necessary for traditional parametric tests.

Whether you are dealing with small datasets, complex model structures, or non-standard data distributions, the `calc_pval` function and the principles of permutation testing described here provide a clear and intuitive framework for assessing the significance of your model coefficients!
