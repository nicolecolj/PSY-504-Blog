---
title: "Permutation Tests with Multinomial Logistic Regression"
author: "Nicole Johnson"
date: "2024-05-08"
categories: [code, statistics]
image: "graph1.JPG"
---

This tutorial will guide you through the implementation of permutation testing for assessing the significance of coefficients in a multinomial logistic regression model using R. The function `calc_pval` is provided for this purpose, which we will dissect step by step to understand its components and usage.

## Overview of Permutation Testing

Permutation testing is a versatile non-parametric statistical tool that allows researchers to test hypotheses about relationships within their data without relying on traditional assumptions about the underlying distribution of the data. This method is particularly useful in fields where the normality assumption does not hold or is difficult to verify.

### Principle of Permutation Testing

At its core, permutation testing involves randomly rearranging (permuting) the labels or values of a dataset and recalculating the statistic of interest, such as a correlation coefficient or regression coefficient, across many such rearranged samples. The idea is to generate a distribution of the statistic under the null hypothesis, which states that there is no association between the variables being tested.

### Steps in Permutation Testing

1.  **Define the Test Statistic**: First, identify the statistic that you will use to measure the association between variables. In the case of regression analysis, this could be the coefficients of the regression model.

2.  **Calculate the Observed Statistic**: Compute the test statistic with the original, unpermuted data. This gives you the observed value that you will compare against the results of the permuted datasets.

3.  **Permute and Recalculate**: Shuffle or permute the outcome variable or the labels of the data while keeping the structure of the data otherwise the same. Then, recalculate the test statistic for this permuted data. This process is repeated a large number of times (commonly 1,000 or more) to build up a distribution of the statistic under the null hypothesis.

4.  **Determine Significance**: Compare your observed test statistic to the distribution obtained from the permuted data. The p-value is calculated as the proportion of permuted statistics that are as extreme as or more extreme than the observed statistic. A small p-value (typically less than 0.05) suggests that the observed association is unlikely to have occurred by chance under the null hypothesis.

## Advantages of Permutation Testing for Multinomial Regressions

Permutation testing is particularly suited for calculating p-values in the context of multinomial logistic regression for several reasons. This method provides robust and reliable significance testing that can be superior to traditional methods, especially when standard assumptions are violated or when the data structure is complex.

1.  **Non-Parametric Approach:** Multinomial logistic regression models, which predict categorical outcomes with more than two categories, often struggle with issues like non-normality of residuals and complex, nonlinear relationships between variables. Permutation testing is a non-parametric technique, meaning it does not rely on assumptions about the distribution of the variables or the form of the model. This characteristic makes it highly suitable for the categorical nature of the data in multinomial logistic regression, where such assumptions cannot be validated easily.
2.  **Empirical P-values:** Permutation testing generates empirical p-values based on the data itself, rather than relying on theoretical distributions. This is done by repeatedly shuffling the outcome variable and recalculating the model coefficients for each shuffled dataset. By comparing the observed coefficients to those from these permuted datasets, we can directly observe how extreme the actual coefficients are within the context of a null hypothesis where no predictors have a real effect on the outcomes. This direct approach is particularly useful in complex models where theoretical distributions may not adequately reflect the reality of the data.
3.  **Handling Complex Model Structures:** In multinomial logistic regression, dealing with multiple outcomes and potentially a large set of predictors can introduce complexity in interpreting interaction effects and the overall significance of predictors. Permutation testing simplifies this by treating the model as a whole during the permutation process, maintaining the structure of the data but breaking any real association between the predictors and the outcomes by shuffling. This method allows for an intuitive assessment of whether observed relationships in the data are likely to be due to chance.
4.  **Robustness Against Overfitting and Model Assumptions:** Multinomial logistic models can easily overfit, especially with a large number of predictors or complex interactions. Standard tests might falsely indicate predictors as significant due to overfitting or other violations of model assumptions (like independence of observations, homoscedasticity, etc.). Permutation testing does not assume these conditions and inherently provides a check against overfitting by evaluating how the model performance (through its coefficients) holds up under randomized conditions.
5.  **Flexibility and Adaptability:** Permutation testing is adaptable to various model specifications and data structures without the need for adjusting the fundamental approach. Whether dealing with highly imbalanced classes, different sample sizes, or unusual data distributions, permutation testing remains applicable and reliable, making it a versatile tool in statistical analysis.
6.  **Validation of Statistical Significance:** Using permutation testing to calculate p-values provides a straightforward and conceptually simple method to validate the statistical significance of coefficients in a multinomial logistic regression. This method can be particularly persuasive when presenting findings to a broader audience, including those who may not be familiar with the intricacies of more complex statistical methodologies.

## Tutorial on Permutation Testing for P-Values in Multinomial Regression

### Function Description: `calc_pval`

The function `calc_pval` performs a permutation test on a multinomial logistic regression model fitted with specified predictors and an outcome. The function requires several inputs: - `df`: A dataframe containing the data. - `outcome`: The name of the outcome variable in the dataframe. - `predictors`: A vector of predictor variables. - `nreps`: The number of permutations to perform.

### Function Breakdown

1.  **Creating the Model Formula**:

    -   Constructs a formula for the multinomial logistic regression model using the outcome and predictors.

    ``` r
    f <- formula(paste(outcome, paste(predictors, collapse = " + "), sep = " ~ "))
    print(f)
    ```

2.  **Fitting the Model**:

    -   Fits a multinomial logistic regression model using the `multinom` function from the `nnet` package. This model is our "observed" model.

    ``` r
    model <- multinom(formula=f, data=df, family="binomial")
    ```

3.  **Permutation Testing**:

    -   Initializes a loop to perform `nreps` permutations of the outcome variable.
    -   For each permutation, it shuffles the outcome variable, fits a new model, and stores the coefficients.

    ``` r
    while (i < nreps){
      loop_df <- data.frame(df)
      loop_df[, outcome] <- sample(loop_df[, outcome])
      loop_model <- multinom(formula=f, data=loop_df, family="binomial", trace=FALSE)
      coefs_null[, , i + 1] <- summary(loop_model)$coefficients
      i <- i + 1
    }
    ```

4.  **Calculating P-Values**:

    -   Compares the observed coefficients to the distribution of coefficients from the permuted data.
    -   Calculates two-tailed p-values for each coefficient by finding how often the permuted coefficients are as extreme as the observed coefficients.

    ``` r
    for (lev in model$lev[-1]){ # excluding the reference category
      null_class <- coefs_null[lev, , ]
      for (coefname in model$coefnames){
        coef_measured <- summary(model)$coefficients[lev, coefname]
        coef_left <- min(coef_measured, -coef_measured)
        coef_right <- max(coef_measured, -coef_measured)
        coef_pleft <- sum(null_class[coefname, ]<=coef_left) / nreps
        coef_pright <- sum(null_class[coefname, ]>=coef_right) / nreps
        row_pvals <- c(row_pvals, coef_pleft + coef_pright)
      }
      pvals[n,] <- row_pvals
      n <- n + 1
    }
    ```

### Usage

To use `calc_pval`, you need a dataframe `df` that includes at least one categorical outcome variable and one or more predictor variables. Specify the outcome variable, a list of predictor variable names, and the number of permutations you want to perform. Here's an example call:

``` r
result_pvals <- calc_pval(df = your_data, outcome = "YourOutcomeVariable", predictors = c("Predictor1", "Predictor2"), nreps = 1000)
print(result_pvals)
```

### I hope this was helpful!

Permutation testing offers a robust and adaptable approach to evaluating the significance of predictors in multinomial logistic regression models. By utilizing the `calc_pval` function as demonstrated in this tutorial, researchers can leverage this non-parametric method to conduct hypothesis testing without relying on the assumptions necessary for traditional parametric tests.

Whether you are dealing with small datasets, complex model structures, or non-standard data distributions, the `calc_pval` function and the principles of permutation testing described here provide a clear and intuitive framework for assessing the significance of your model coefficients!
