[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Permutation Tests with Multinomial Logistic Regression",
    "section": "",
    "text": "This tutorial will guide you through the implementation of permutation testing for assessing the significance of coefficients in a multinomial logistic regression model using R. The function calc_pval is provided for this purpose, which we will dissect step by step to understand its components and usage."
  },
  {
    "objectID": "posts/post-with-code/index.html#overview-of-permutation-testing",
    "href": "posts/post-with-code/index.html#overview-of-permutation-testing",
    "title": "Permutation Tests with Multinomial Logistic Regression",
    "section": "Overview of Permutation Testing",
    "text": "Overview of Permutation Testing\nPermutation testing is a versatile non-parametric statistical tool that allows researchers to test hypotheses about relationships within their data without relying on traditional assumptions about the underlying distribution of the data. This method is particularly useful in fields where the normality assumption does not hold or is difficult to verify.\n\nPrinciple of Permutation Testing\nAt its core, permutation testing involves randomly rearranging (permuting) the labels or values of a dataset and recalculating the statistic of interest, such as a correlation coefficient or regression coefficient, across many such rearranged samples. The idea is to generate a distribution of the statistic under the null hypothesis, which states that there is no association between the variables being tested.\n\n\nSteps in Permutation Testing\n\nDefine the Test Statistic: First, identify the statistic that you will use to measure the association between variables. In the case of regression analysis, this could be the coefficients of the regression model.\nCalculate the Observed Statistic: Compute the test statistic with the original, unpermuted data. This gives you the observed value that you will compare against the results of the permuted datasets.\nPermute and Recalculate: Shuffle or permute the outcome variable or the labels of the data while keeping the structure of the data otherwise the same. Then, recalculate the test statistic for this permuted data. This process is repeated a large number of times (commonly 1,000 or more) to build up a distribution of the statistic under the null hypothesis.\nDetermine Significance: Compare your observed test statistic to the distribution obtained from the permuted data. The p-value is calculated as the proportion of permuted statistics that are as extreme as or more extreme than the observed statistic. A small p-value (typically less than 0.05) suggests that the observed association is unlikely to have occurred by chance under the null hypothesis."
  },
  {
    "objectID": "posts/post-with-code/index.html#advantages-of-permutation-testing-for-multinomial-regressions",
    "href": "posts/post-with-code/index.html#advantages-of-permutation-testing-for-multinomial-regressions",
    "title": "Permutation Tests with Multinomial Logistic Regression",
    "section": "Advantages of Permutation Testing for Multinomial Regressions",
    "text": "Advantages of Permutation Testing for Multinomial Regressions\n\nBut first, what is multinomial regression?\nIn binary logistic regression, the outcome is typically modeled with a logistic function predicting the probability of one of the two categories, given a set of independent variables. Multinomial logistic regression generalizes this approach to multiple categories by using a series of logistic equations to compare each category to a reference category. The probabilities derived from these equations are relative to the reference category, which is usually chosen automatically by the software or can be manually specified.\n\nModel Formulation\nThe model estimates the probabilities of being in each category of the dependent variable as a function of the independent variables. It does this through what are known as the log-odds or logit transformations, where each category (except the reference category) will have its own set of regression coefficients.\nMathematically, if you have a response variable (Y) with (K) possible outcomes, the probability of (Y) equaling a particular category (k) can be modeled as:\n[ P(Y = k X) = ]\nwhere (X_1, X_2, , X_p) are the predictor variables, and (,* , , _{kp}) are the coefficients for category (k).\n\n\nEstimation\nThe coefficients (_{kj}) are typically estimated using maximum likelihood estimation (MLE). This method seeks to find the set of coefficients that maximize the likelihood of observing the sample given the model.\n\n\nInterpretation\nInterpreting the coefficients in multinomial logistic regression is similar to binary logistic regression, but instead of comparing the log-odds of the outcome to a “no event” condition, each coefficient represents the log-odds of being in the target category relative to the reference category, given a one-unit change in the predictor.\n\n\n\nApplying Permutation Testing\nPermutation testing is particularly suited for calculating p-values in the context of multinomial logistic regression for several reasons. This method provides robust and reliable significance testing that can be superior to traditional methods, especially when standard assumptions are violated or when the data structure is complex.\n\nNon-Parametric Approach: Multinomial logistic regression models, which predict categorical outcomes with more than two categories, often struggle with issues like non-normality of residuals and complex, nonlinear relationships between variables. Permutation testing is a non-parametric technique, meaning it does not rely on assumptions about the distribution of the variables or the form of the model. This characteristic makes it highly suitable for the categorical nature of the data in multinomial logistic regression, where such assumptions cannot be validated easily.\nEmpirical P-values: Permutation testing generates empirical p-values based on the data itself, rather than relying on theoretical distributions. This is done by repeatedly shuffling the outcome variable and recalculating the model coefficients for each shuffled dataset. By comparing the observed coefficients to those from these permuted datasets, we can directly observe how extreme the actual coefficients are within the context of a null hypothesis where no predictors have a real effect on the outcomes. This direct approach is particularly useful in complex models where theoretical distributions may not adequately reflect the reality of the data.\nHandling Complex Model Structures: In multinomial logistic regression, dealing with multiple outcomes and potentially a large set of predictors can introduce complexity in interpreting interaction effects and the overall significance of predictors. Permutation testing simplifies this by treating the model as a whole during the permutation process, maintaining the structure of the data but breaking any real association between the predictors and the outcomes by shuffling. This method allows for an intuitive assessment of whether observed relationships in the data are likely to be due to chance.\nRobustness Against Overfitting and Model Assumptions: Multinomial logistic models can easily overfit, especially with a large number of predictors or complex interactions. Standard tests might falsely indicate predictors as significant due to overfitting or other violations of model assumptions (like independence of observations, homoscedasticity, etc.). Permutation testing does not assume these conditions and inherently provides a check against overfitting by evaluating how the model performance (through its coefficients) holds up under randomized conditions.\nFlexibility and Adaptability: Permutation testing is adaptable to various model specifications and data structures without the need for adjusting the fundamental approach. Whether dealing with highly imbalanced classes, different sample sizes, or unusual data distributions, permutation testing remains applicable and reliable, making it a versatile tool in statistical analysis.\nValidation of Statistical Significance: Using permutation testing to calculate p-values provides a straightforward and conceptually simple method to validate the statistical significance of coefficients in a multinomial logistic regression. This method can be particularly persuasive when presenting findings to a broader audience, including those who may not be familiar with the intricacies of more complex statistical methodologies."
  },
  {
    "objectID": "posts/post-with-code/index.html#tutorial-on-permutation-testing-for-p-values-in-multinomial-regression",
    "href": "posts/post-with-code/index.html#tutorial-on-permutation-testing-for-p-values-in-multinomial-regression",
    "title": "Permutation Tests with Multinomial Logistic Regression",
    "section": "Tutorial on Permutation Testing for P-Values in Multinomial Regression",
    "text": "Tutorial on Permutation Testing for P-Values in Multinomial Regression\n\nFunction Description: calc_pval\nThe function calc_pval performs a permutation test on a multinomial logistic regression model fitted with specified predictors and an outcome. The function requires several inputs: - df: A dataframe containing the data. - outcome: The name of the outcome variable in the dataframe. - predictors: A vector of predictor variables. - nreps: The number of permutations to perform.\n\n\nFunction Breakdown\n\nCreating the Model Formula:\n\nConstructs a formula for the multinomial logistic regression model using the outcome and predictors.\n\nf &lt;- formula(paste(outcome, paste(predictors, collapse = \" + \"), sep = \" ~ \"))\nprint(f)\nFitting the Model:\n\nFits a multinomial logistic regression model using the multinom function from the nnet package. This model is our “observed” model.\n\nmodel &lt;- multinom(formula=f, data=df, family=\"binomial\")\nPermutation Testing:\n\nInitializes a loop to perform nreps permutations of the outcome variable.\nFor each permutation, it shuffles the outcome variable, fits a new model, and stores the coefficients.\n\nwhile (i &lt; nreps){\n  loop_df &lt;- data.frame(df)\n  loop_df[, outcome] &lt;- sample(loop_df[, outcome])\n  loop_model &lt;- multinom(formula=f, data=loop_df, family=\"binomial\", trace=FALSE)\n  coefs_null[, , i + 1] &lt;- summary(loop_model)$coefficients\n  i &lt;- i + 1\n}\nCalculating P-Values:\n\nCompares the observed coefficients to the distribution of coefficients from the permuted data.\nCalculates two-tailed p-values for each coefficient by finding how often the permuted coefficients are as extreme as the observed coefficients.\n\nfor (lev in model$lev[-1]){ # excluding the reference category\n  null_class &lt;- coefs_null[lev, , ]\n  for (coefname in model$coefnames){\n    coef_measured &lt;- summary(model)$coefficients[lev, coefname]\n    coef_left &lt;- min(coef_measured, -coef_measured)\n    coef_right &lt;- max(coef_measured, -coef_measured)\n    coef_pleft &lt;- sum(null_class[coefname, ]&lt;=coef_left) / nreps\n    coef_pright &lt;- sum(null_class[coefname, ]&gt;=coef_right) / nreps\n    row_pvals &lt;- c(row_pvals, coef_pleft + coef_pright)\n  }\n  pvals[n,] &lt;- row_pvals\n  n &lt;- n + 1\n}\n\n\n\nUsage\nTo use calc_pval, you need a dataframe df that includes at least one categorical outcome variable and one or more predictor variables. Specify the outcome variable, a list of predictor variable names, and the number of permutations you want to perform. Here’s an example call:\nresult_pvals &lt;- calc_pval(df = your_data, outcome = \"YourOutcomeVariable\", predictors = c(\"Predictor1\", \"Predictor2\"), nreps = 1000)\nprint(result_pvals)\n\n\nExample Dataset: College Major Choice\nSuppose we have a dataset from a survey of college students. The dataset includes the following variables:\n\nMajor: The student’s chosen major (Business, Engineering, Humanities - categorical, with Humanities as the reference category).\nMath_Score: Score on a mathematics aptitude test (continuous).\nVerbal_Score: Score on a verbal aptitude test (continuous).\nGender: Male or Female (binary, categorical).\n\nWe want to model the probability of a student choosing Business or Engineering over Humanities, based on their math and verbal scores and gender.\n\n\nBuilding the Model\nUsing R, we can specify our multinomial logistic regression model like this:\nlibrary(nnet)  \n\nmodel &lt;- multinom(Major ~ Math_Score + Verbal_Score + Gender, data = df)\n\n\nModel Output Interpretation\nThe output of the model would give us a set of coefficients for Business and Engineering, relative to Humanities. Here’s how you might interpret these coefficients:\n\nIntercept for Business: The log-odds of choosing Business over Humanities when all other variables are zero.\nMath_Score for Business: The change in log-odds of choosing Business over Humanities for a one-unit increase in Math_Score, holding other variables constant.\nVerbal_Score for Business: Similar to Math_Score, but for Verbal_Score.\nGender for Business: The change in log-odds of choosing Business over Humanities if the student is male (assuming ‘Male’ is coded as 1).\n\n\n\nExample Interpretation:\nLet’s say the coefficients for Business relative to Humanities are as follows:\n\nIntercept: -1.50\nMath_Score: 0.10\nVerbal_Score: 0.05\nGender (Male): 0.25\n\nThis means: - For every one-point increase in Math_Score, the log-odds of choosing Business over Humanities increases by 0.10. - Being male increases the log-odds of choosing Business over Humanities by 0.25 compared to being female.\n\n\nPermutation Testing\nPermutation testing in this context would involve: 1. Calculating the Observed Statistic: Compute the regression coefficients with the original data. 2. Permutation: Randomly shuffle the Major categories among the students while keeping the predictors the same. 3. Recompute Coefficients: Fit the regression model to each permuted dataset and calculate the coefficients. 4. Comparison and P-Value Calculation: Compare the observed coefficients to those obtained from the permuted datasets. The p-value for each coefficient is calculated as the proportion of times the permuted coefficients are as extreme as or more extreme than the observed coefficients.\n\n\nInterpreting the Permutation Test:\nSuppose the p-value for the Gender (Male) coefficient in choosing Business over Humanities is 0.03. This suggests that the observed relationship between gender and major choice is statistically significant at a conventional alpha level of 0.05 (i.e., there is only a 3% chance that such an extreme coefficient would be observed if there was no actual association between gender and major choice).\n\n\nI hope this was helpful!\nPermutation testing offers a robust and adaptable approach to evaluating the significance of predictors in multinomial logistic regression models. By utilizing the calc_pval function as demonstrated in this tutorial, researchers can leverage this non-parametric method to conduct hypothesis testing without relying on the assumptions necessary for traditional parametric tests.\nWhether you are dealing with small datasets, complex model structures, or non-standard data distributions, the calc_pval function and the principles of permutation testing described here provide a clear and intuitive framework for assessing the significance of your model coefficients!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Nicole Johnson Blog",
    "section": "",
    "text": "Permutation Tests with Multinomial Logistic Regression\n\n\n\n\n\n\ncode\n\n\nstatistics\n\n\n\n\n\n\n\n\n\nMay 8, 2024\n\n\nNicole Johnson\n\n\n\n\n\n\nNo matching items"
  }
]